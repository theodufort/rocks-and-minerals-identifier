{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Clones\\rocks-and-minerals-identifier\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading datasets...\n",
            "\n",
            "Dataset 1 (mineralimage5K-98-combined):\n",
            "  Splits: ['train']\n",
            "  Train size: 18326\n",
            "  Features: dict_keys(['image', 'label'])\n",
            "  Label type: <class 'datasets.features.features.Value'>\n",
            "\n",
            "Dataset 2 (Minerals_type_images1-combined):\n",
            "  Splits: ['train']\n",
            "  Train size: 43762\n",
            "  Features: dict_keys(['image', 'label'])\n",
            "  Label type: <class 'datasets.features.features.Value'>\n"
          ]
        }
      ],
      "source": [
        "# Combine two datasets: mineralimage5K-98-combined and Minerals_type_images1-combined\n",
        "from datasets import load_from_disk, concatenate_datasets, DatasetDict, ClassLabel, Value\n",
        "import pandas as pd\n",
        "\n",
        "# Load both datasets\n",
        "print(\"Loading datasets...\")\n",
        "ds1 = load_from_disk(\"./mineralimage5K-98/mineralimage5K-98-combined\")\n",
        "ds2 = load_from_disk(\"./Minerals_type_images1/Minerals_type_images1-combined\")\n",
        "\n",
        "print(f\"\\nDataset 1 (mineralimage5K-98-combined):\")\n",
        "print(f\"  Splits: {list(ds1.keys())}\")\n",
        "print(f\"  Train size: {len(ds1['train'])}\")\n",
        "print(f\"  Features: {ds1['train'].features.keys()}\")\n",
        "print(f\"  Label type: {type(ds1['train'].features['label'])}\")\n",
        "\n",
        "print(f\"\\nDataset 2 (Minerals_type_images1-combined):\")\n",
        "print(f\"  Splits: {list(ds2.keys())}\")\n",
        "print(f\"  Train size: {len(ds2['train'])}\")\n",
        "print(f\"  Features: {ds2['train'].features.keys()}\")\n",
        "print(f\"  Label type: {type(ds2['train'].features['label'])}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checking and normalizing label types...\n",
            "Dataset 1: Label already string type\n",
            "Dataset 2: Label already string type\n",
            "\n",
            "After normalization:\n",
            "  Dataset 1 features: dict_keys(['image', 'label'])\n",
            "  Dataset 2 features: dict_keys(['image', 'label'])\n",
            "  Dataset 1 label type: <class 'datasets.features.features.Value'>\n",
            "  Dataset 2 label type: <class 'datasets.features.features.Value'>\n",
            "\n",
            "Ensuring all labels are lowercase strings...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 18326/18326 [00:12<00:00, 1481.03 examples/s]\n",
            "Map: 100%|██████████| 43762/43762 [00:38<00:00, 1123.49 examples/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ✓ All labels normalized to lowercase strings\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Normalize labels to strings for both datasets and then combine\n",
        "train1 = ds1['train']\n",
        "train2 = ds2['train']\n",
        "\n",
        "# Check label types and convert to strings if needed\n",
        "label_feature1 = train1.features.get('label')\n",
        "label_feature2 = train2.features.get('label')\n",
        "\n",
        "print(\"Checking and normalizing label types...\")\n",
        "\n",
        "# Convert dataset 1 labels to strings if it's ClassLabel\n",
        "if isinstance(label_feature1, ClassLabel):\n",
        "    print(\"Dataset 1: Converting ClassLabel to string\")\n",
        "    def convert_label1_to_string(example):\n",
        "        if 'label' in example:\n",
        "            label_idx = example['label']\n",
        "            if isinstance(label_idx, int):\n",
        "                example['label'] = label_feature1.names[label_idx]\n",
        "        return example\n",
        "    train1 = train1.map(convert_label1_to_string)\n",
        "    train1 = train1.cast_column('label', Value('string'))\n",
        "    print(\"  ✓ Converted to string\")\n",
        "else:\n",
        "    print(\"Dataset 1: Label already string type\")\n",
        "\n",
        "# Convert dataset 2 labels to strings if it's ClassLabel\n",
        "if isinstance(label_feature2, ClassLabel):\n",
        "    print(\"Dataset 2: Converting ClassLabel to string\")\n",
        "    def convert_label2_to_string(example):\n",
        "        if 'label' in example:\n",
        "            label_idx = example['label']\n",
        "            if isinstance(label_idx, int):\n",
        "                example['label'] = label_feature2.names[label_idx]\n",
        "        return example\n",
        "    train2 = train2.map(convert_label2_to_string)\n",
        "    train2 = train2.cast_column('label', Value('string'))\n",
        "    print(\"  ✓ Converted to string\")\n",
        "else:\n",
        "    print(\"Dataset 2: Label already string type\")\n",
        "\n",
        "# Verify both have matching features\n",
        "print(f\"\\nAfter normalization:\")\n",
        "print(f\"  Dataset 1 features: {train1.features.keys()}\")\n",
        "print(f\"  Dataset 2 features: {train2.features.keys()}\")\n",
        "print(f\"  Dataset 1 label type: {type(train1.features['label'])}\")\n",
        "print(f\"  Dataset 2 label type: {type(train2.features['label'])}\")\n",
        "\n",
        "# Ensure both have lowercase string labels\n",
        "print(\"\\nEnsuring all labels are lowercase strings...\")\n",
        "def ensure_lowercase_string(example):\n",
        "    if 'label' in example and example['label']:\n",
        "        example['label'] = str(example['label']).lower()\n",
        "    return example\n",
        "\n",
        "train1 = train1.map(ensure_lowercase_string)\n",
        "train2 = train2.map(ensure_lowercase_string)\n",
        "print(\"  ✓ All labels normalized to lowercase strings\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Combining datasets...\n",
            "  Dataset 1 size: 18326\n",
            "  Dataset 2 size: 43762\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting the dataset: 100%|██████████| 18326/18326 [00:14<00:00, 1243.42 examples/s]\n",
            "Casting the dataset: 100%|██████████| 43762/43762 [00:19<00:00, 2269.23 examples/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Combined dataset size: 62088\n",
            "Combined features: dict_keys(['image', 'label'])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving the dataset (23/23 shards): 100%|██████████| 62088/62088 [01:07<00:00, 915.57 examples/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✓ Combined dataset exported successfully to: ./combined-datasets\n",
            "\n",
            "==================================================\n",
            "DATASET COMBINATION SUMMARY\n",
            "==================================================\n",
            "Total examples: 62088\n",
            "  - From mineralimage5K-98: 18326\n",
            "  - From Minerals_type_images1: 43762\n",
            "\n",
            "Features: ['image', 'label']\n",
            "Label type: <class 'datasets.features.features.Value'>\n",
            "\n",
            "Total unique labels: 5246\n",
            "\n",
            "Sample labels (first 10):\n",
            "  1. 'abellaite': 12 examples\n",
            "  2. 'abelsonite': 1 examples\n",
            "  3. 'abenakiite-(ce)': 2 examples\n",
            "  4. 'abernathyite': 20 examples\n",
            "  5. 'abhurite': 16 examples\n",
            "  6. 'abramovite': 5 examples\n",
            "  7. 'abuite': 1 examples\n",
            "  8. 'acanthite': 20 examples\n",
            "  9. 'acetamide': 1 examples\n",
            "  10. 'achalaite': 1 examples\n",
            "  ... and 5236 more\n"
          ]
        }
      ],
      "source": [
        "# Combine both datasets into one\n",
        "print(\"Combining datasets...\")\n",
        "print(f\"  Dataset 1 size: {len(train1)}\")\n",
        "print(f\"  Dataset 2 size: {len(train2)}\")\n",
        "\n",
        "# Ensure both datasets have matching feature types for concatenation\n",
        "# Cast both to have the same feature schema\n",
        "from datasets import Features, Image\n",
        "\n",
        "# Create a common feature schema\n",
        "common_features = Features({\n",
        "    'image': Image(),\n",
        "    'label': Value('string')\n",
        "})\n",
        "\n",
        "train1 = train1.cast(common_features)\n",
        "train2 = train2.cast(common_features)\n",
        "\n",
        "# Concatenate the datasets\n",
        "combined_train = concatenate_datasets([train1, train2])\n",
        "\n",
        "print(f\"\\nCombined dataset size: {len(combined_train)}\")\n",
        "print(f\"Combined features: {combined_train.features.keys()}\")\n",
        "\n",
        "# Create DatasetDict with combined train split\n",
        "ds_combined = DatasetDict({\"train\": combined_train})\n",
        "\n",
        "# Export the combined dataset\n",
        "export_path = \"./combined-datasets\"\n",
        "ds_combined.save_to_disk(export_path)\n",
        "\n",
        "print(f\"\\n✓ Combined dataset exported successfully to: {export_path}\")\n",
        "\n",
        "# Show statistics\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"DATASET COMBINATION SUMMARY\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Total examples: {len(combined_train)}\")\n",
        "print(f\"  - From mineralimage5K-98: {len(train1)}\")\n",
        "print(f\"  - From Minerals_type_images1: {len(train2)}\")\n",
        "print(f\"\\nFeatures: {list(combined_train.features.keys())}\")\n",
        "print(f\"Label type: {type(combined_train.features['label'])}\")\n",
        "\n",
        "# Show unique labels count and sample\n",
        "unique_labels = sorted(set(combined_train['label']))\n",
        "print(f\"\\nTotal unique labels: {len(unique_labels)}\")\n",
        "print(f\"\\nSample labels (first 10):\")\n",
        "for i, label in enumerate(unique_labels[:10]):\n",
        "    count = combined_train['label'].count(label)\n",
        "    print(f\"  {i+1}. '{label}': {count} examples\")\n",
        "if len(unique_labels) > 10:\n",
        "    print(f\"  ... and {len(unique_labels) - 10} more\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
